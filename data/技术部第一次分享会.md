# 机器学习导论

### 一、机器学习的本质定义

#### 1. 核心目标

让计算机**从数据中自动学习规律**，无需显式编程就能完成特定任务（比如预测、分类、决策）。

→ 对比传统编程：传统编程是「输入规则 + 数据→输出结果」，机器学习是「输入数据 + 结果→输出规则」。

也就是说机器学习学习的东西就是如何创建一个规则，把输入的数据应用于这个规则得到正确的输出。

#### 2. 核心术语

* **数据**：学习的原材料（如图片、表格、文本），分为「特征（输入）」和「标签（输出 / 目标）」；
* **模型**：可以理解为机器学习的「最终成果」。它就本质上就是根据海量数据训练出的“智能函数”（例如 y = f(x)）。给它一个输入（x，如一张猫的图片），它就能根据学到的规则（可以理解为函数里写的逻辑处理代码），输出一个预测结果（y，如“猫”这个标签）。它本质上就是那套解决特定问题的“方法”或“大脑”。
* **训练**：模型从数据中找规律的过程（制定规则的过程）；
* **泛化能力**：模型在「新数据」上的表现（核心评价标准，避免 “死记硬背” 数据）；
* **范式**：模型学习规律的「方式」（即 “如何利用数据”），核心取决于「是否有标签」「是否有反馈」。可以理解为机器学习的「学习流派」或「训练模式」。它决定了模型用什么样的方法论从数据中学习。就像人有不同的学习方式（跟着老师学、自己探索、反复试错），机器学习也根据数据和反馈机制的不同，分化出了几个主流的“流派”。

> 此处为了方便同学理解，我们采用了通俗的比喻，严谨的定义详细看到我们后面要阅读的鱼书

---

### 二、三大主流学习范式

#### （一）有监督学习

##### 1. 核心特征：有「标签」的 “老师教学”

* 数据特点：每个样本都有明确的「输入（特征）→输出（标签）」对应关系（如 “图片→猫 / 狗”“房屋面积→房价”）；
* 学习目标：学习「输入到输出的映射关系」（Y = f (X)），让模型能对新输入预测出正确标签。

##### 2. 两大核心任务

| 任务类型 | 输出类型                    | 典型场景                         | 传统实现方法          | 深度学习实现方法                         |
| -------- | --------------------------- | -------------------------------- | --------------------- | ---------------------------------------- |
| 分类     | 离散标签（如 0/1、猫 / 狗） | 垃圾邮件识别、图像识别、疾病诊断 | 逻辑回归、决策树、SVM | CNN（图像分类）、Transformer（文本分类） |
| 回归     | 连续标签（如价格、温度）    | 房价预测、股票走势预测、销量预估 | 线性回归、随机森林    | 全连接神经网络、LSTM（时序回归）         |

##### 3. 关键注意点

* 标签质量决定模型上限（“老师教错了，学生再努力也没用”）；
* 常见问题：
  * 过拟合（相当于模型“做作业”来回只看那几道题，考试时题目稍微变换一下就不行了）
  * 欠拟合（相当于模型题刷少了，考试时每道题回答得都差点意思）

---

#### （二）无监督学习

##### 1. 核心特征：无「标签」的 “自主探索”

* 数据特点：只有输入特征（X），没有预设标签（Y）；
* 学习目标：发现数据本身的「内在结构 / 规律」（如聚类、隐藏特征），无需外部指导。

##### 2. 三大核心任务

| 任务类型 | 定义                       | 典型场景                         | 传统实现方法        | 深度学习实现方法                         |
| -------- | -------------------------- | -------------------------------- | ------------------- | ---------------------------------------- |
| 聚类     | 按相似性将数据分组         | 客户分群、异常检测（如欺诈交易） | K-Means、DBSCAN     | 聚类算法 + 神经网络特征提取              |
| 降维     | 保留核心信息，减少特征维度 | 高维数据可视化、数据压缩         | PCA、LDA            | 自编码器（Autoencoder）、TSNE            |
| 生成任务 | 学习数据分布，生成新样本   | 图像生成、文本续写               | 高斯混合模型（GMM） | GAN（生成对抗网络）、VAE（变分自编码器） |

##### 3. 关键注意点

* 无明确 “对错” 标准（如聚类结果是否合理需结合业务判断）；
* 核心价值：挖掘数据中人类难以发现的隐藏规律。

---

#### （三）强化学习

##### 1. 核心特征：基于「奖励反馈」的 “试错学习”

* 核心逻辑：**就像训练宠物** 。智能体（Agent，比如一只小狗）在特定环境（Environment，比如客厅）中不断尝试各种动作（Action，比如“坐下”或“打滚”）。当它做出正确的动作时，你会给它奖励（Reward，比如零食）；做错了则没有奖励或受到温和的惩罚。通过反复试错，小狗最终会学会一套能获得最多零食的行为模式（即“策略”）。
* 数据特点：无预设标签，数据是「交互过程中产生的序列」（状态 S→动作 A→奖励 R→新状态 S'）。

##### 2. 核心要素

* 智能体（Agent）：学习的主体（如自动驾驶汽车、游戏 AI）；
* 环境（Environment）：智能体交互的场景（如道路、游戏地图）；
* 状态（State）：环境的当前情况（如汽车位置、游戏血量）；
* 动作（Action）：智能体的决策（如转弯、攻击）；
* 奖励（Reward）：环境对动作的反馈（如通关 + 100 分、撞车 - 100 分）。

##### 3. 典型任务

| 任务类型 | 场景举例             | 传统实现方法           | 深度学习实现方法                        |
| -------- | -------------------- | ---------------------- | --------------------------------------- |
| 决策优化 | 自动驾驶、机器人控制 | Q-Learning、Sarsa      | DQN（深度 Q 网络）、PPO（近端策略优化） |
| 游戏竞技 | 围棋 AI、游戏通关    | 蒙特卡洛树搜索（MCTS） | AlphaGo（MCTS+CNN）、DOTA2 AI           |

##### 4. 关键注意点

* 学习过程可能 “耗时耗力”（如 AlphaGo 需大量棋局训练）；
* 核心价值：解决「无明确指导、需长期决策」的复杂问题（传统有监督 / 无监督难以覆盖）。

---

### 三、范式对比与核心区别

| 维度         | 有监督学习              | 无监督学习           | 强化学习                    |
| ------------ | ----------------------- | -------------------- | --------------------------- |
| 数据要求     | 带标签的样本数据        | 无标签的特征数据     | 交互产生的序列数据          |
| 学习方式     | 模仿标签（归纳映射）    | 探索结构（发现规律） | 试错 + 奖励反馈（优化策略） |
| 核心目标     | 预测准确                | 结构清晰 / 生成合理  | 累积奖励最大                |
| 典型评价指标 | 准确率、MSE（均方误差） | 聚类纯度、重构误差   | 累积奖励值                  |

---

### 四、模型实现方法的本质

#### 1. 为什么深度学习不单独列为范式？

* 深度学习的核心是「深度神经网络」（多层感知机、CNN、Transformer 等），本质是「模型的 “载体 / 结构”」；
* 同一深度学习结构可适配不同范式：

  * 有监督：CNN 做图像分类（输入图片 + 标签→学习映射）；
  * 无监督：自编码器做特征降维（输入图片→学习隐藏特征）；
  * 强化学习：DQN 用神经网络拟合 Q 函数（输入状态→输出选择这个动作的价值是多少）。

#### 2. 实现方法的分类逻辑

| 实现方法类型         | 代表模型                  | 适配范式                                       |
| -------------------- | ------------------------- | ---------------------------------------------- |
| 传统线性模型         | 线性回归、逻辑回归        | 有监督（主要）、无监督（如 PCA）               |
| 树模型               | 决策树、随机森林、XGBoost | 有监督（主要）、无监督（如孤立森林做异常检测） |
| 神经网络（深度学习） | CNN、RNN、Transformer     | 三大范式均适配                                 |

---

### 五、学习路径

1. 作为入门者，我们会优先带大家掌握「有监督学习」，因为它最直观、应用范围最广；
2. 「无监督学习」（解决无标签数据场景）我们仅做简单科普，大家可以私下实践；
3. 最后探索「强化学习」（复杂决策问题，需先掌握前两者基础）；

---

# 深度学习导论

本导论从最基础的感知机出发，逐步引入可导激活、损失函数与反向传播，说明深度学习训练的核心流程。

## 目标简介

- 输入：带标签的数据集 (X, y)。其中X是输入的数据样本，y是其输出的真实标签对照。可以看作带着答案的练习册，X视题目，y是标准答案。
- 模型：由若干层线性变换与非线性激活构成（例如全连接层 + ReLU/Sigmoid）。就像是学生的大脑，内部有很多“神经元”，好比知识点连接逻辑。
- 深度学习训练的关键步骤：前向——计算预测；损失——衡量误差；反向——计算梯度；更新——沿梯度方向调整参数。
- 训练目标：前向（让模型不断做题）-> 计算损失并反向（对答案并订正） -> 更新（学会解题通用解法）

> 此处为了方便理解，我们用通俗的概念进行比喻，更严谨的定义详见鱼书

## 1 感知机（Perceptron）与线性判别

感知机是最简单的线性分类器。给定输入向量 x、权重向量 w 和偏置 b：

- 线性组合：z = w·x + b
- 激活函数（原始感知机）：ŷ = sign(z)   （此处激活函数在鱼书中有详细说明，为引入了非线性的变化）

下面为感知机的简单示意图

![感知机示意](https://raw.githubusercontent.com/3030Scar/mdg/3a58e1a3b44ef844d9b3c2ee481cb96e21e51c64/data/img/perceptron.svg)

## 2 深度学习的基本训练流程（概览）

1. 设计模型结构：确定层数、每层神经元数与激活函数。（决定学生的知识结构，是文科生还是理科生、大脑有多少容量）
2. 初始化参数：初始化权重与偏置。（学生刚开始都是瞎猜的知识点，处于一种“蒙”的状态）
3. 前向传播：逐层计算线性变换与激活，得到预测输出。（学生尝试做一道练习题，给出自己的答案/预测值）
4. 计算损失：用损失函数 L(预测, 真实) 衡量误差。（老师拿出答案对比学生的答案给出差评度/损失）
5. 反向传播：用链式法则计算每个参数对损失的梯度。（老师告诉学生哪错了，引导学生订正）
6. 参数更新：利用梯度下降或其变种（SGD、Momentum、Adam）更新参数。（学生根据老师的指点/梯度更正解题思路/更新参数）
7. 重复以上步骤直至收敛或达到停止条件。（不断地做题、对答案、改正，直到学生在大部分练习题上表现都很好）

## 3 损失函数

损失函数将模型的输出映射为一个实数标量，表示模型预测与真实标签的差距。损失函数的梯度告诉我们应如何调整参数以减少误差：梯度的方向是损失上升最快的方向，取其相反方向则能局部减少损失。

常见损失函数示例

- 二分类：二元交叉熵（binary cross-entropy）。
- 多分类：Softmax + 交叉熵。
- 回归：均方误差（MSE）。

## 4 损失与参数更新：图像演示

下面两张图示意了损失函数与参数更新的直观含义，展示了在该损失函数曲线上的单步梯度更新过程。

### 损失曲线示意

![损失曲线示意](https://github.com/3030Scar/mdg/blob/main/data/img/62322011b1ec524535008bd1b05e0a29.png?raw=true)

图注说明（对应图中标记）：

- 横轴表示某一标量参数（或参数向量在一条方向上的投影）w（此处是θ）；纵轴表示对应的损失 L(w)（此处是J（θ））。
- 曲线显示了损失随参数变化的形状。
- 当前点表示当前参数值处的损失高度，即当前预测值与实际值的距离，切线斜率给出局部导数（梯度）信息。

直观解释：如果切线在当前点向上（梯度为正），说明在该方向上增加参数会增加损失；梯度为负则说明增加参数会降低损失。因而参数更新沿梯度的负方向移动，以减少损失。

> 通俗比喻：“想象一下，你（参数）正站在一座大山（损失函数）上，四周伸手不见五指，你的目标是走到山谷的最低点（最小损失）。
>
> 你该怎么走呢？最直接的办法是，用脚感受一下你当前位置哪个方向是下坡最陡峭的（这就是梯度的反方向），然后朝着这个方向走一小步。
>
> 每走一步，你都重复这个过程：感受坡度最陡的方向，然后迈出下一步。这样，虽然你看不见全局，但一步步走下去，有很大概率能到达一个山谷的底部。这个过程就是梯度下降。”

## 5 单样本数值示例

考虑最简单的场景：单个输入样本与单个输出，模型由权重 w 与偏置 b 控制，通过激活函数输出概率。输入样本，样本经过神经网络前向计算得到预测概率（相当于进行了一次小测），代入损失函数得到单样本损失（得到了小测的成绩）。反向传播得到梯度（根据当前小测的成绩找到需要进一步学习改正的方向），再按学习率尺度更新参数（再根据方向按照合适的尺度进行学习更新）。更新后重新进行预测，通常会看到损失下降，说明参数朝着降低误差的方向移动。

**e.g:**

> 假设我们有一个超级简单的模型 y = w * x（为了简单，先忽略偏置 b 和激活函数）。
>
> 样本：我们拿到一道题 x=2，标准答案是 y=6。
> 初始化：模型刚开始是瞎猜的，比如它猜 w=2。
>
> 1. 前向预测：模型计算 y_pred = w * x = 2 * 2 = 4。
> 2. 计算损失：老师说标准答案是 6，你答了 4，差了 2（误差 = 6 - 4 = 2）。损失（比如用平方误差）就是 (6-4)² = 4。
> 3. 反向传播：老师指出，你的答案偏小了，说明你的权重 w 可能也偏小了。梯度计算会给出一个明确的信号：“w 需要增大”。
> 4. 更新参数：模型听从指导，把 w 增大一点，比如更新到 w=2.5。
>    下一轮学习：
> 5. 再次预测：模型用新的知识 w=2.5 再算一次，y_pred = 2.5 * 2 = 5。
> 6. 新的损失：这次答案是 5，比上次的 4 更接近标准答案 6 了。损失变成了 (6-5)² = 1。损失变小了！
>    这就说明，模型通过一轮学习，确实进步了。持续这个过程，w 会越来越接近 3。

## 6 小结

从感知机的线性判别起步，引入可导激活与损失函数，使用梯度下降的方法训练参数。损失函数把预测误差转换为对于参数而言的可导信号，反向传播把信号沿链式法则传播到每个参数，优化器据此调整参数逐步降低损失。掌握前向、损失、反向、更新四步，是理解深度学习训练的核心
